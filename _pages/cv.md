---
layout: archive
title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}


## Education

- **MSc in Data Science**, Nazarbayev University, Kazakhstan  
  *Aug 2022 – Jun 2024*  
  GPA: 3.59 / 4.0  
  Thesis: _An Exploration of Video Transformers for Few-Shot Action Recognition_

- **BS in Computer Science**, Nazarbayev University, Kazakhstan  
  *Aug 2018 – Jun 2022*  
  GPA: 3.71 / 4.0 (CS Courses GPA: 3.82 / 4.0)  
  Honors: Diploma of Honor  

## Research Interests
Deep Learning, Computer Vision, Few-Shot Learning, Vision-Language Models.

## Publications

1. **Efficient Facial Expression Recognition Framework Based on Edge Computing**  
   _Journal of Supercomputing (SJR Q2)_, Jan 2024  
   **Aikyn, N.** (First Author), Zhanegizov, A., Aidarov, T., Bui, D. M., & Tu, N. A.  
   [DOI: 10.1007/s11227-023-05548-x](https://doi.org/10.1007/s11227-023-05548-x)

2. **FedFSLAR: A Federated Learning Framework for Few-shot Action Recognition**  
   _2024 IEEE WACV Conference_, Jan 2024  
   Tu, N. A., Abu, A., **Aikyn, N.**, Makhanov, N., Lee, M. H., Le-Huy, K., & Wong, K. S.  
   [DOI: 10.1109/WACVW60836.2024.00035](https://doi.org/10.1109/WACVW60836.2024.00035)

3. **Few-shot Action Recognition with Video Transformer**  
   _2023 IEEE SITIS Conference_, Nov 2023  
   **Aikyn, N.** (First Author), Abu, A., Zhaksylyk, T., & Tu, N. A.  
   [DOI: 10.1109/SITIS61268.2023.00027](https://doi.org/10.1109/SITIS61268.2023.00027)

4.  **Benchmarking Federated Few-shot Learning for Video-based Action Recognition**  
   _Under Revision_  
   Tu, N. A., **Aikyn, N.**, Makhanov, N., Abu, A., Wong, K. S., & Lee, M. H.

5.  **Improving Vision-Language Models with Attention Mechanisms for Aerial Video Classification**  
   _Under Revision_  
   Tu, N. A., **Aikyn, N.**

## Research Experience

- **Research Assistant**  
  Nazarbayev University, Kazakhstan  
  *Jul 2022 – Present*
  
  Contributed to the project: Edge-assisted activity recognition using skeletal representation and deep learning for video surveillance.
  
  Focus areas: Deep Learning, Computer Vision, Few-Shot Learning, Federated Learning, Human Action Recognition, Facial Expression Recognition, Edge Computing, Vision Transformers, Vision-Language Models.

  Worked on tasks:

  1. **Vision-Language Models for Aerial Video Classification**  
   Jun 2024 - present  
      - Adapted vision-language models (e.g., CLIP) to aerial video datasets (ERA, UAV-Human, MOD20), enhancing frame sampling, prompt generation, and temporal aggregation for action detection.
      - Conducted extensive testing in zero-shot, few-shot, and fully supervised settings, with an ablation study to optimize methods, achieving SOTA results on benchmark datasets.

  2. **Federated Few-Shot Action Recognition**  
   Aug 2023 - Jul 2024  
      - Contributed to integrating few-shot learning in federated learning frameworks. Conducted experiments with meta-learning techniques (e.g., Prototypical Networks, Reptile) on MViT, Slow-Fast, and R(2+1)D models under both IID and non-IID federated settings.
      - Conducted extensive testing in zero-shot, few-shot, and fully supervised settings, with an ablation study to optimize methods, achieving SOTA results on benchmark datasets.

  3. **Few-Shot Learning for Action Recognition with Video Transformers**  
   Jan 2023 - Nov 2023  
      - Developed a few-shot action recognition framework with Transformer-based backbones (TimeSformer, Swin Transformer, MViT) and ProtoNet for metric-based meta-learning.
      - Implemented self-supervised pretraining on custom datasets and leveraged pretraining on large datasets to boost transformer model performance in 1-shot and 5-shot tasks.

  4. **Transformer-Based Multi-Stream Human Action Recognition**  
   Jul 2022 - Jan 2023  
      - Built multi-stream models integrating RGB, optical flow, and skeletal data via feature-level fusion, achieving near-SOTA results through transfer learning and keyframe sampling.


  5. **Facial Expression Recognition (FER) on Edge Systems**  
   Jan 2022 - Nov 2022  
      - Designed a FER framework optimized for edge devices, combining deep learning and edge computing for low-latency, privacy-preserving emotion recognition.
      - Achieved real-time FER with landmark-based feature engineering and lightweight models, matching SOTA accuracy on resource-constrained devices.


## Achievements and Activities

- Presented paper _Few-shot Action Recognition with Video Transformer_ at SITIS 2023 in Bangkok, Thailand, Nov 2023
- Third Prize at the International Mathematics Competition, Blagoevgrad, Bulgaria, Aug 2019.
- Gold Medal in the SIAM Mathematics Olympics, Nazarbayev University, Feb 2019.

## Teaching Assistant Experience

- **CSCI 390 - Artificial Intelligence**, Nazarbayev University  
  _Fall 2022, 2023, 2024_  
  Assisted in proctoring exams and grading.

- **CSCI 152 - Data Structures and Performance**, Nazarbayev University  
  _Spring 2024_  
  Managed lab sessions and graded assignments and exams.

## Skills

- **Programming Languages**: Python, Java, C++, C, C#, Lua, Prolog, Javascript  
- **Frameworks & Tools**: PyTorch, OpenCV, TensorFlow, Keras, SciKit-Learn, MySQL, Linux, Git  
- **Languages**: English (Proficient, IELTS band 7.5), Kazakh (Native), Chinese (Native)
